---
title: "R Tutorial"
author: "Griffin Dietz, adapted from Mike Frank's Tidyverse Tutorial"
date: "11/14/2019"
output: html_document
---

Starting note: The best reference for this material is Hadley Wickham's [R for data scientists](http://r4ds.had.co.nz/)

If you have tidyverse installed, you can `knit` the tutorial into an HTML document for better readability by pressing the `knit` button at the top.

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
```

<!-- ----------------------------------------------------------------------- -->
# Goals and Introduction

By the end of this tutorial, you will know:

+ What "tidy data" is and why it's an awesome format
+ How to do some stuff with tidy data
+ How to get your data to be tidy
+ How to run/interpret some widely-used statistical tests in R

In order to do that, we'll start by introducing the concepts of **tidy data** and **functions and pipes**.

## Tidy data

> “Tidy datasets are all alike, but every messy dataset is messy in its own way.” –– Hadley Wickham

Here's the basic idea: In tidy data, every row is a single **observation** (trial), and every column describes a **variable** with some **value** describing that trial. 

And if you know that data are formatted this way, then you can do amazing things, basically because you can take a uniform approach to the dataset. From R4DS:

"There’s a general advantage to picking one consistent way of storing data. If you have a consistent data structure, it’s easier to learn the tools that work with it because they have an underlying uniformity. There’s a specific advantage to placing variables in columns because it allows R’s vectorised nature to shine."

## Functions and Pipes

Everything you typically want to do in statistical programming uses **functions**. `mean` is a good example. `mean` takes one **argument**, a numeric vector. Pipes are a way to write strings of functions more easily. They bring the first argument of the function to the beginning. 

We'll use the `mtcars` dataset that's built in with the `tidyverse` and look at the `mpg` variable (miles per gallon). Instead of writing `mean(mtcars$mpg)`, with a pipe you can write:

```{r}
mtcars$mpg %>% mean
```

That's not very useful yet, but when you start **nesting** functions, it gets better. 

```{r}
gpm <- function (mpg) {1/mpg} # gallons per mile, maybe better than miles per gallon. 
```

**Exercise.** Rewrite the following with pipes. Run this code chunk to verify they output the same result.
```{r}
round(mean(gpm(mtcars$mpg)), digits = 2)

# Rewrite piped version here
```

This can be super helpful for writing strings of functions so that they are readable and distinct. We'll be doing a lot of piping of functions with multiple arguments later, and it will really help keep our syntax simple. 

<!-- ----------------------------------------------------------------------- -->
# Tidy Data Analysis with `dplyr`

Reference: [R4DS Chapter 5](http://r4ds.had.co.nz/transform.html)

Let's take a psychological dataset. Here are the raw data from [Stiller, Goodman, & Frank (2015)](http://langcog.stanford.edu/papers_new/SGF-LLD-2015.pdf). Children met a puppet named "Furble." Furble would show them three pictures, e.g. face, face with glasses, face with hat and glasses and would say "my friend has glasses." They then had to choose which face was Furble's friend. (The prediction was that they'd choose *glasses and not a hat*, indicating that they'd made a correct pragmatic inference). In the control condition, Furble just mumbled. 

These data are tidy: each row describes a single trial, each column describes some aspect of tha trial, including their id (`subid`), age (`age`), condition (`condition` - "label" is the experimental condition, "No Label" is the control), item (`item` - which thing Furble was trying to find). 

We are going to manipulate these data using "functions" from `dplyr`. I'll only teach four functions, the most common in my workflow (but there are many other useful ones):

+ `filter` - remove rows by some logical condition
+ `mutate` - create new columns 
+ `group_by` - group the data into subsets by some column
+ `summarize` - apply some function over columns in each group  

## Exploring and characterizing the dataset

```{r}
sgf <- read_csv("data/stiller_scales_data.csv")
sgf
```

Inspect the various variables before you start any analysis. You can use `summary` to see, well, a summary of each variable. 

```{r}
summary(sgf)
```

I personally prefer interactive tools like `View` that allow you to see the full data table.

```{r, eval=FALSE}
View(sgf)
```

## Filtering & Mutating

There are lots of reasons you might want to remove *rows* from your dataset, including getting rid of outliers, selecting subpopulations, etc. `filter` is a function that takes a data frame as its first argument, and then as its second takes the **condition** you want to filter on. 

So if you wanted to look only at two year olds, you could do this. (Note you can give two conditions, could also do `age >= 2 & age < 3`). (equivalent: `filter(sgf, age >= 2, age < 3)`)

Note that we're going to be using pipes with functions over data frames here. The way this works is that:

+ `tidyverse` functions always take the data frame as their first argument, and
+ because pipes pull out the first argument, the data frame just gets passed through successive operations
+ so you can read a pipe chain as "take this data frame and first do this, then do this, then do that."

This is essentially the huge insight of `dplyr`: you can chain functions into readable and efficient sequences of operations over dataframes, provided 1) the functions all have the same syntax (which they do) and 2) the data all have the same structure (which they do if they are tidy). 

OK, so filtering:

```{r}
sgf %>%
  filter(age >= 2, 
         age < 3) 
```

**Exercise.** Filter out only the "faces" trial in the "Label" condition. Any rows that are not "faces" trials in the "Label" condition should remain in the table.

```{r}

```

Next up, *adding columns*. You might do this perhaps to compute some kind of derived variable. `mutate` is the function for these situations - it allows you to add a column. Let's add a discrete age group factor to our dataset.

```{r}
sgf <- sgf %>%
  mutate(age_group = cut(age, 2:5, include.lowest = TRUE))

head(sgf$age_group)
```

**Exercise.** Now let's imagine we want to slit the data into two age groups: younger (2 and 3 year olds) and older (4 and 5 year olds). Create a new factor called age_split that has the values "younger" and "older" according to these specifications.
```{r}

```


## Standard descriptives using `summarise` and `group_by`

We typically describe datasets at the level of subjects, not trials. We need two functions to get a summary at the level of subjects: `group_by` and `summarise` (kiwi spelling). Grouping alone doesn't do much.

```{r}
sgf %>%
  group_by(age_group) 
```

All it does is add a grouping marker. 

What `summarise` does is to *apply a function* to a part of the dataset to create a new summary dataset. So we can apply the function `mean` to the dataset and get the grand mean. 

```{r}
## DO NOT DO THIS!!!
# foo <- initialize_the_thing_being_bound()
# for (i in 1:length(unique(sgf$item))) {
#   for (j in 1:length(unique(sgf$condition))) {
#     this_data <- sgf[sgf$item == unique(sgf$item)[i] & 
#                       sgf$condition == unique(sgf$condition)[n],]
#     do_a_thing(this_data)
#     bind_together_somehow(this_data)
#   }
# }

sgf %>%
  summarise(correct = mean(correct))
```
Note the syntax here: `summarise` takes multiple `new_column_name = function_to_be_applied_to_data(data_column)` entries in a list. Using this syntax, we can create more elaborate summary datasets also:

```{r}
sgf %>%
  summarise(correct = mean(correct), 
            n_observations = length(subid))
```

Where these two functions shine is in combination, though. Because `summarise` applies functions to columns in your *grouped data*, not just to the whole dataset!

So we can group by age or condition or whatever else we want and then carry out the same procedure, and all of a sudden we are doing something extremely useful!

```{r}
sgf_means <- sgf %>%
  group_by(age_group, condition) %>%
  summarise(correct = mean(correct), 
            n_observations = length(subid))
sgf_means
```

These summary data are typically very useful for plotting. .

```{r}
ggplot(sgf_means, 
       aes(x = age_group, y = correct, col = condition, group = condition)) + 
  geom_line() + 
  ylim(0,1) +
  theme_classic()
```

**Exercise**. Adapt the code above to split the data by item, rather than age group. **BONUS**: plot the data this way as well.  

```{r}

```


<!-- ----------------------------------------------------------------------- -->
# Getting to Tidy with `tidyr`

Reference: [R4DS Chapter 12](http://r4ds.had.co.nz/tidy-data.html)

Data often comes in two flavors: *long* and *wide* data. Long form data is *tidy*, but that format is less common. It's much more common to get *wide* data, in which every row is a case (e.g., a subject), and each column is a variable. In this format multiple trials (observations) are stored as columns. This can go a bunch of ways, for example, the most common might be to have subjects as rows and trials as columns. 

For example, let's take a look at a wide version of the `sgf` dataset above. 

```{r}
sgf_wide <- read_csv("data/sgf_wide.csv")
head(sgf_wide)
```

The two main functions for tidying are `gather` and `spread`. (There are lots of others in the `tidyr` package if you want to split or merge columns etc.). 

Here, we'll just show how to use `gather` to make the data tidy; we'll try to make a single column called `item` and a single column called `correct` rather than having four different columns, one for each item. 

`gather` takes three arguments:

- a `tidyselect` way of getting columns. This is the columns you want to make longer. You can select them by name (e.g. `beds, faces, houses, pasta`), you can use numbers (e.g., `5:8`), or you can use markers like `starts_with(...)`.
- a `names_to` argument. this argument is the **name of the column names**. in this case, the column names are items, so the "missing label" for them is `item`.
- a `values_to` argument. this is the name of the thing in each column, in this case, the accuracy of the response (`correct`). 

Let's try it:

```{r}
sgf_tidy <- sgf_wide %>% 
  gather(beds:pasta, 
               key = "item", 
               value = "correct")
sgf_tidy
```
We can compare this to `sgf` and see that we've recovered the original long form. (This is good, because I used `spread` to *make* the `sgf_wide` dataframe). 

**Exercise.** Use `spread` to try and make `sgf_wide` from `sgf`. The two arguments you need are `key` and `value`, which specify the names and values (just like in `gather`). 
```{r}

```

<!-- ----------------------------------------------------------------------- -->
# Analyses

These extras are fun things to go through at the end of the tutorial, time permitting. Because they require more data and packages, they are set by default not to evaluate if you knit the tutorial. 

## T-tests
T tests allow us to compare means between groups. The syntax of a t-test is t.test(y~x,data) where y is the dependent variable and x is the independent variable. That is, is there a difference in y between the two groups in x.

Let's take a look at the ToothGrowth dataset. It contains the results from an experiment studying the effect of vitamin C on tooth growth in 60 Guinea pigs. Each animal received one of three dose levels of vitamin C (0.5, 1, and 2 mg/day) by one of two delivery methods, (orange juice or ascorbic acid (a form of vitamin C and coded as VC).

```{r}
head(ToothGrowth)
```

Imagine we want to determine if there is a difference in tooth growth between the two delivery methods.

First, let's visualize the data.
```{r}
ggplot(ToothGrowth,aes(x = supp, y = len)) + 
  stat_summary(fun.y=mean, geom="bar")
```

Next, we can use a t-test to determine if there is a significant difference in tooth growth between the two delivery methods.

```{r}
t.test(len ~ supp, data=ToothGrowth) 
```
We can see here that the p-value is >.05, which is the significance level (alpha) we've chosen that allows us to reject the null hypothesis. Therefore we cannot conclude that delivery method had an impact on tooth length.

## ANOVA
Let's start by taking a look at the Iris dataset, a commonly used example dataset built into the dplyr package. It contains three plant species (setosa, virginica, versicolor) and four features measured for each sample.
```{r}
head(iris)
```

ANOVA allow us to compare means between more than 2 groups. The syntax of an ANOVA is very similar to that of a t-test: aov(y~x,data).

Imagine we want to determine if there is a difference in sepal length between the three species:
First, let's visualize the data.
```{r}
ggplot(iris,aes(x = Species, y = Sepal.Length)) + 
  stat_summary(fun.y=mean, geom="bar")
```

Next, we can use an ANOVA to determine if there is a significant difference in sepal width between the three species.
```{r}
sepal_width_anova <- aov(Sepal.Width ~ Species, data=iris) 
summary(sepal_width_anova)
```
We can see here that the p-value is <.05, which is the significance level (alpha) we've chosen that allows us to reject the null hypothesis. We can therefore accept the alternative hypothesis: the differences between at least one of the means is statistically significant. However, we cannot from this test determine which species differs fromt he others.

One option is to use a Tukey's Honest Significant Difference post-hoc test to conduct pair-wise comparisons between each group.
```{r}
TukeyHSD(sepal_width_anova)
```

We can see here that the p adj value (adjusted p value) is less than our alpha of .05 in all three pairwise comparisons. This means there is a significant difference between all three species' means.

**Exercise.** Determine if there is a significant difference in petal length between the three species. First visualize the data. Then use an ANOVA to determine if there is a difference between any groups. If there is a difference, ise a post-hoc test to determine which groups differ.
```{r}

```

## Linear Regression
Finally let's take a look at the cars dataset. This dataset has the stopping distance of different cars (ft) and the speed that car was travelling (mph) before stopping.
```{r}
head(cars)
```

Let's see if we can predict stopping distance by speed. To do this we can use a linear regression, which allows us to build a model to predict the value of one continuos variable based on another continuous variable.

But first, visualize the data!
```{r}
ggplot(cars,aes(x = speed, y = dist)) + 
  geom_point()
```

Next, we can use a linear regression to determine if we can predict stopping distants by speed.
```{r}
model <- lm(dist~speed,cars)
summary(model)
```
 
We can see here that the p-value is <.05, which is the significance level (alpha) we've chosen that allows us to reject the null hypothesis. We can therefore accept that we can predict stopping distance by speed. Furthermore, by examining the "Estimate" value, we can state that our model predicts that every time speed goes up by 1, the stopping distance will increase by 3.93.


**Exercise.** Let's look back at the iris dataset. Can we predict sepal width based on sepal length? Don't forget to visualize the data.
```{r}

```

